[{"path":"https://stevenpawley.github.io/colino/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2019 Steven Pawley Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://stevenpawley.github.io/colino/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Steven Pawley. Author, maintainer. Max Kuhn. Author. Rowan Jacques-Hamilton. Author.","code":""},{"path":"https://stevenpawley.github.io/colino/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Pawley S, Kuhn M, Jacques-Hamilton R (2022). colino: Recipes Steps Supervised Filter-Based Feature Selection. R package version 0.0.1, https://stevenpawley.github.io/colino.","code":"@Manual{,   title = {colino: Recipes Steps for Supervised Filter-Based Feature Selection},   author = {Steven Pawley and Max Kuhn and Rowan Jacques-Hamilton},   year = {2022},   note = {R package version 0.0.1},   url = {https://stevenpawley.github.io/colino}, }"},{"path":"https://stevenpawley.github.io/colino/index.html","id":"colino","dir":"","previous_headings":"","what":"Recipes Steps for Supervised Filter-Based Feature Selection","title":"Recipes Steps for Supervised Filter-Based Feature Selection","text":"goal colino provide supervised feature selection steps used tidymodels recipes package. Note - colino new package name replaces preliminary ‘recipeselectors’ name. Colino submitted CRAN additional steps documentation finalized.","code":""},{"path":"https://stevenpawley.github.io/colino/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Recipes Steps for Supervised Filter-Based Feature Selection","text":"","code":"devtools::install_github(\"stevenpawley/colino\")"},{"path":"https://stevenpawley.github.io/colino/index.html","id":"feature-selection-methods","dir":"","previous_headings":"","what":"Feature Selection Methods","title":"Recipes Steps for Supervised Filter-Based Feature Selection","text":"following feature selection methods implemented: step_select_infgain provides Information Gain feature selection. step requires FSelectorRcpp package installed can used classification regression problems. regression, target variable discretized using equal frequency binning. step_select_mrmr provides maximum Relevancy Minimum Redundancy feature selection. step requires praznik package installed. step can used classification regression problems. Similar information gain, binning used target variable continuous. step_select_roc provides ROC-based feature selection based predictors’ relationship response outcomes measured using Receiver Operating Characteristic curve. step_select_xtab provides feature selection using statistical association. step_select_vip provides model-based selection using feature importance scores coefficients. method allows parsnip model specification used select subset features based models’ feature importances coefficients. See details. step_select_boruta provides Boruta feature selection step. step can used classification regression problems. step_select_carscore provides CAR score feature selection step regression models. step requires care package installed. step_select_relief provides Relief-based feature selection step classification regression models. step requires FSelectorRcpp package installed. step_select_forests, step_select_tree, step_select_linear provide model-based methods selecting subset features based model’s feature importance scores coefficients.","code":""},{"path":"https://stevenpawley.github.io/colino/index.html","id":"planned-methods","dir":"","previous_headings":"Feature Selection Methods","what":"Planned methods","title":"Recipes Steps for Supervised Filter-Based Feature Selection","text":"step_select_fstatistic using ANOVA classification r2 converted f-statistic regression step_select_chi2 classifications","code":""},{"path":"https://stevenpawley.github.io/colino/index.html","id":"notes","dir":"","previous_headings":"","what":"Notes","title":"Recipes Steps for Supervised Filter-Based Feature Selection","text":"focus colino provide extra recipes filter-based feature selection. step_select_vip designed work parsnip package requires base model specification provides method ranking importance features, feature importance scores coefficients, one score per feature. base model specified step using model parameter. Although step_select_vip allows diverse range models used ranking algorithm, potentially allows new models implemented, limitation hyperparameters ranking model tuned. alternative, step_select_linear, step_select_tree step_select_forests provide steps specific types models hyperparameters ranking model can tuned using tuning arguments parsnip. parsnip package currently contain method pulling feature importance scores models support . colino package provides generic function pull_importances purpose accepts fitted parsnip model, returns tibble two columns ‘feature’ ‘importance’: models ‘engines’ provide feature importances implemented. addition, h2o models supported using agua package. Use methods(pull_importances) list models currently implemented. need pull feature importance scores model currently supported package, can add class pull_importances generic function returns two-column tibble: example using step_importance function:","code":"model <- boost_tree(mode = \"classification\") %>%   set_engine(\"xgboost\")  model_fit <- model %>%    fit(Species ~., iris)  pull_importances(model_fit) pull_importances._ranger <- function(object, scaled = FALSE, ...) {   scores <- ranger::importance(object$fit)    # create a tibble with 'feature' and 'importance' columns   scores <- tibble::tibble(     feature = names(scores),     importance = as.numeric(scores)   )    # optionally rescale the importance scores   if (scaled)     scores$importance <- scales::rescale(scores$importance)   scores } library(parsnip) library(recipes) library(magrittr)  # load the example iris dataset data(iris)  # define a base model to use for feature importances base_model <- rand_forest(mode = \"classification\") %>%   set_engine(\"ranger\", importance = \"permutation\")  # create a preprocessing recipe rec <- iris %>% recipe(Species ~ .) %>% step_select_vip(all_predictors(), model = base_model, top_p = 2,                 outcome = \"Species\")  prepped <- prep(rec)  # create a model specification clf <- decision_tree(mode = \"classification\") %>% set_engine(\"rpart\")  clf_fitted <- clf %>%   fit(Species ~ ., juice(prepped))"},{"path":"https://stevenpawley.github.io/colino/reference/colino.html","id":null,"dir":"Reference","previous_headings":"","what":"colino: A collection of steps for feature selection to use with the\n'recipes' package — colino","title":"colino: A collection of steps for feature selection to use with the\n'recipes' package — colino","text":"colino provides collection additional step objects related feature selection used 'recipes' package.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/colino.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"colino: A collection of steps for feature selection to use with the\n'recipes' package — colino","text":"Steven Pawley, dr.stevenpawley@gmail.com","code":""},{"path":"https://stevenpawley.github.io/colino/reference/colino.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"colino: A collection of steps for feature selection to use with the\n'recipes' package — colino","text":"","code":"library(parsnip) library(recipes) library(magrittr)  # load the example iris dataset data(iris)  # define a base model to use for feature importances base_model <- rand_forest(mode = \"classification\") %>%     set_engine(\"ranger\", importance = \"permutation\")  # create a preprocessing recipe rec <- iris %>%  recipe(Species ~ .) %>%  step_select_vip(all_predictors(), model = base_model, top_p = 2,                  outcome = \"Species\")  prepped <- prep(rec)  # create a model specification clf <- decision_tree(mode = \"classification\") %>%     set_engine(\"rpart\")  clf_fitted <- clf %>%     fit(Species ~ ., juice(prepped))"},{"path":"https://stevenpawley.github.io/colino/reference/entropy.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter functions for feature selection recipes — entropy","title":"Parameter functions for feature selection recipes — entropy","text":"Entropy-based feature selection methods can applied using several methods calculate entropy formula. `entropy` specifying type entropy-based filter used.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/entropy.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameter functions for feature selection recipes — entropy","text":"","code":"entropy(values = values_entropy)"},{"path":"https://stevenpawley.github.io/colino/reference/entropy.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter functions for feature selection recipes — entropy","text":"values character string possible values. See `values_entropy` possible values.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/entropy.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameter functions for feature selection recipes — entropy","text":"function classes \"qual_param\" \"param\"","code":""},{"path":"https://stevenpawley.github.io/colino/reference/entropy.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameter functions for feature selection recipes — entropy","text":"","code":"entropy('infogain') #> Warning: The `default` argument of `new_qual_param()` is deprecated as of dials 1.0.1. #> ℹ The deprecated feature was likely used in the colino package. #>   Please report the issue at <https://github.com/stevenpawley/colino/issues>. #> Method used for entropy-based feature selection  (qualitative) #> 1 possible value include: #> 'infogain'"},{"path":"https://stevenpawley.github.io/colino/reference/pipe.html","id":null,"dir":"Reference","previous_headings":"","what":"Pipe operator — %>%","title":"Pipe operator — %>%","text":"See magrittr::%>% details.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/pipe.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pipe operator — %>%","text":"","code":"lhs %>% rhs"},{"path":"https://stevenpawley.github.io/colino/reference/pull_importances.html","id":null,"dir":"Reference","previous_headings":"","what":"Pull feature importances from a parsnip fitted model — pull_importances","title":"Pull feature importances from a parsnip fitted model — pull_importances","text":"`pull_importances` generic function extract feature importance scores coefficients parsnip `model_fit` object return tibble 'feature' 'importance' column. designed support `step_importance` recipe step.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/pull_importances.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Pull feature importances from a parsnip fitted model — pull_importances","text":"","code":"pull_importances(object, scaled = TRUE, ...)"},{"path":"https://stevenpawley.github.io/colino/reference/pull_importances.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Pull feature importances from a parsnip fitted model — pull_importances","text":"object `model_fit` object. scaled logical indicating whether rescale importances 0 1. Default TRUE. ... list parameters passed feature importance method.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/pull_importances.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Pull feature importances from a parsnip fitted model — pull_importances","text":"tibble","code":""},{"path":"https://stevenpawley.github.io/colino/reference/pull_importances.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Pull feature importances from a parsnip fitted model — pull_importances","text":"basic models within parsnip package support feature importances implemented (call `methods(pull_importances)` list models currently implemented). need pull feature importance scores model currently supported package, can add class pull_importances generic function returns two-column tibble:","code":""},{"path":"https://stevenpawley.github.io/colino/reference/pull_importances.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Pull feature importances from a parsnip fitted model — pull_importances","text":"","code":"library(parsnip)  # pull feature importances from a model_fit object model <- boost_tree(mode = \"classification\") %>%     set_engine(\"xgboost\") model_fit <- model %>% fit(Species ~., iris) #> Error in check_installs(object): This engine requires some package installs: 'xgboost' pull_importances(model_fit) #> Error in pull_importances(model_fit): object 'model_fit' not found  # create a new pull_importances method pull_importances._ranger <- function(object, scaled = FALSE, ...) {     # create a call to the ranger::importance function avoiding having to use     # ranger as a dependency     call <- rlang::call2(.fn = \"importance\", .ns = \"ranger\", x = object$fit)     scores <- rlang::eval_tidy(call)      # create a tibble with 'feature' and 'importance' columns     scores <- tibble::tibble(       feature = names(scores),       importance = as.numeric(scores)     )     # optionally rescale the importance scores     if (isTRUE(scaled))       scores$importance <- rescale(scores$importance)      scores }"},{"path":"https://stevenpawley.github.io/colino/reference/required_pkgs.embed.html","id":null,"dir":"Reference","previous_headings":"","what":"S3 methods for tracking which additional packages are needed for steps. — required_pkgs.step_select_fcbf","title":"S3 methods for tracking which additional packages are needed for steps. — required_pkgs.step_select_fcbf","text":"Recipe-adjacent packages always list required package steps can function properly within parallel processing schemes.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/required_pkgs.embed.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"S3 methods for tracking which additional packages are needed for steps. — required_pkgs.step_select_fcbf","text":"","code":"# S3 method for step_select_fcbf required_pkgs(x, ...)"},{"path":"https://stevenpawley.github.io/colino/reference/required_pkgs.embed.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"S3 methods for tracking which additional packages are needed for steps. — required_pkgs.step_select_fcbf","text":"x recipe step","code":""},{"path":"https://stevenpawley.github.io/colino/reference/required_pkgs.embed.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"S3 methods for tracking which additional packages are needed for steps. — required_pkgs.step_select_fcbf","text":"character vector","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_boruta.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature selection step using Boruta — step_select_boruta","title":"Feature selection step using Boruta — step_select_boruta","text":"`step_select_boruta` creates *specification* recipe step selects subset predictors using Boruta feature selection approach.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_boruta.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature selection step using Boruta — step_select_boruta","text":"","code":"step_select_boruta(   recipe,   ...,   outcome = NULL,   role = \"predictor\",   trained = FALSE,   exclude = NULL,   options = list(pValue = 0.01, mcAdj = TRUE, maxRuns = 100),   res = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_boruta\") )  # S3 method for step_select_boruta tidy(x, type = \"terms\", ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_boruta.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature selection step using Boruta — step_select_boruta","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables affected step. See selections() details. tidy method, currently used. outcome character string name response variable use calculate feature importance scores. role used step since new variables created. trained logical indicate quantities preprocessing estimated. exclude character vector predictor names removed data. set `prep()` used recipe set user. options list options pass `Boruta::Boruta()`. defaults use Boruta's defaults. *Note* `x` `y` passed . res `Boruta::Boruta` object stored preprocessing step trained `prep.recipe()`. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_boruta` object. type character either 'terms' (default) return tibble containing variables removed filter step, 'scores' return scores variable.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_boruta.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature selection step using Boruta — step_select_boruta","text":"`step_select_boruta` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_boruta.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Feature selection step using Boruta — step_select_boruta","text":"Boruta algorithm technically wrapper approach uses random forests test whether feature importance scores obtained original data higher best scores obtained variables randomly permuted. permuted features termed 'shadow' features. scores original feature higher best scores randomly permuted features, marked 'hit'. Features confirmed rejected based confidence threshold (default p = 0.01) applied tails binomial distribution p = 0.5. Features fall within lower (reject) upper (accept) tails distribution labelled 'tentative'. Rejected features dropped feature set procedure repeated 'tentative' features exist, maximum number runs reached.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_boruta.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature selection step using Boruta — step_select_boruta","text":"","code":"library(recipes) library(parsnip)  # load the example iris dataset data(cells, package = \"modeldata\")  # create a preprocessing recipe rec <-  recipe(class ~ ., data = cells[, -1]) %>%  step_select_boruta(all_predictors(), outcome = \"class\")  prepped <- prep(rec)  preproc_data <- juice(prepped) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         56 #>  #> Training data contained 2019 data points and no missing data. #>  #> Operations: #>  #> Boruta feature selection (5 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_carscore.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature selection step using the CAR score algorithm — step_select_carscore","title":"Feature selection step using the CAR score algorithm — step_select_carscore","text":"`step_select_carscore` creates *specification* recipe step selects subset predictors part regression model based scores CAR score algorithm. step requires `care` package installed. top `top_p` scoring features, features whose scores occur top percentile `threshold` retained new predictors.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_carscore.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature selection step using the CAR score algorithm — step_select_carscore","text":"","code":"step_select_carscore(   recipe,   ...,   outcome = NULL,   role = NA,   trained = FALSE,   top_p = NA,   threshold = NA,   lambda = NA,   diagonal = FALSE,   exclude = NULL,   scores = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_carscore\") )  # S3 method for step_select_carscore tidy(x, type = \"terms\", ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_carscore.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature selection step using the CAR score algorithm — step_select_carscore","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables affected step. See selections() details. tidy method, currently used. outcome character string name response variable. must refer numeric feature regression. role used step since new variables created. trained logical indicate quantities preprocessing estimated. top_p integer number best scoring features select. threshold numeric value 0 1 representing percentile best scoring features select. Features scores _larger_ specified threshold retained, example `threshold = 0.9` retain predictors scores top 90th percentile. Note overrides `top_p`. lambda correlation shrinkage intensity (range 0-1). diagonal diagonal = FALSE (default) CAR scores computed; otherwise diagonal = TRUE marginal correlations. exclude character vector predictor names removed data. set `prep()` used recipe set user. scores tibble 'variable' 'scores' columns containing names variables absolute values calculated CAR scores. parameter produced recipe trained. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_carscore` object. type character either 'terms' (default) return tibble containing variables removed filter step, 'scores' return scores variable.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_carscore.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature selection step using the CAR score algorithm — step_select_carscore","text":"step_select_carscore object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_carscore.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Feature selection step using the CAR score algorithm — step_select_carscore","text":"recipe stop `top_p` `threshold` left unspecified.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_carscore.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature selection step using the CAR score algorithm — step_select_carscore","text":"","code":"library(recipes)  data(car_prices, package = \"modeldata\")  rec <-  recipe(Price ~ ., data = car_prices) %>%  step_select_carscore(    all_predictors(),    outcome = \"Price\",    top_p = 5,    threshold = 0.7  )  prepped <- prep(rec) #> Estimating optimal shrinkage intensity lambda (correlation matrix): 0.025   new_data <- bake(prepped, new_data = NULL) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         17 #>  #> Training data contained 804 data points and no missing data. #>  #> Operations: #>  #> Carscore feature selection (12 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_fcbf.html","id":null,"dir":"Reference","previous_headings":"","what":"Fast Correlation Based Filter for Feature Selection — step_select_fcbf","title":"Fast Correlation Based Filter for Feature Selection — step_select_fcbf","text":"step_select_fcbf takes set features performs fast correlation based filter, resulting smaller subset features selected. number features selected depends min_su threshold parameter (lower threshold selects features).","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_fcbf.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Fast Correlation Based Filter for Feature Selection — step_select_fcbf","text":"","code":"step_select_fcbf(   recipe,   ...,   min_su = 0.025,   outcome = NA,   cutpoint = 0.5,   features_retained = NA,   role = NA,   trained = FALSE,   removals = NULL,   skip = FALSE,   id = rand_id(\"select_fcbf\") )"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_fcbf.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Fast Correlation Based Filter for Feature Selection — step_select_fcbf","text":"recipe recipe object. step added sequence operations recipe. ... Selector functions specify features considered FCBF, e.g., all_numeric_predictors(), all_predictors(). min_su Minimum threshold symmetrical uncertainty. Lower values allow features selected. outcome Outcome variable used filter selection. one outcome variable recipe, automatically detected. multiple outcome variables exist, user specify . cutpoint Quantile value (0-1) describing split numeric features binary nominal features. e.g. 0.5 = median split features_retained Internal object gives record features retained FCBF. specified user. role used step since new variables created. trained logical indicate quantities preprocessing estimated. removals Feature columns removed. Used internally set user. skip logical. step skipped recipe baked bake()? operations baked prep() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify .","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_fcbf.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Fast Correlation Based Filter for Feature Selection — step_select_fcbf","text":"Returns recipe object, step_select_fcbf added   sequence operations recipe.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_fcbf.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Fast Correlation Based Filter for Feature Selection — step_select_fcbf","text":"step_select_fcbf takes range features (e.g. full feature   set) selects subset features using FCBF algorithm described   Yu, L. Liu, H. (2003). FCBF selects features simultaneously minimize correlation features maximise correlations features target. FCBF works categorical features, continuous features must first discretized. default based median split (.e. splitting continuous variables 'high' versus 'low'), method may customized internal function 'discretize_var'. Code implement FCBF algorithm driven Bioconductor package 'FCBF'. step_select_fcbf provides wrappers allow used within tidymodels framework","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_fcbf.html","id":"references","dir":"Reference","previous_headings":"","what":"References","title":"Fast Correlation Based Filter for Feature Selection — step_select_fcbf","text":"Yu, L. Liu, H. (2003); Feature Selection High-Dimensional   Data Fast Correlation Based Filter Solution, Proc. 20th Intl. Conf. Mach.   Learn. (ICML-2003), Washington DC, 2003.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_forests.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature selection step using a random forest feature importance scores — step_select_forests","title":"Feature selection step using a random forest feature importance scores — step_select_forests","text":"`step_select_forests` creates *specification* recipe step selects subset predictors based ranking variable importance using `parsnip::rand_forest` supported model.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_forests.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature selection step using a random forest feature importance scores — step_select_forests","text":"","code":"step_select_forests(   recipe,   ...,   outcome = NULL,   role = \"predictor\",   trained = FALSE,   engine = \"ranger\",   options = list(importance = \"permutation\"),   mtry = NULL,   trees = NULL,   min_n = NULL,   top_p = NA,   threshold = NA,   exclude = NULL,   scores = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_forests\") )  # S3 method for step_select_forests tidy(x, type = \"terms\", ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_forests.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature selection step using a random forest feature importance scores — step_select_forests","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables affected step. See selections() details. tidy method, currently used. outcome character string name response variable use calculate feature importance scores. role used step since new variables created. trained logical indicate quantities preprocessing estimated. engine supported rand_forest engine supported parsnip. default \"ranger\". options named list options pass rand_forest engine. example, `engine = 'ranger'` (default) options `list(permutation = 'importance`) feature importance method needs specified engine. default. mtry integer number predictors randomly sampled split creating tree models. trees integer number trees contained ensemble. min_n integer minimum number data points node required node split . top_p integer number best scoring features select. threshold numeric value 0 1 representing percentile best scoring features select. Features scores _larger_ specified threshold retained, example `threshold = 0.9` retain predictors scores top 90th percentile. Note overrides `top_p`. exclude character vector predictor names removed data. set `prep()` used recipe set user. scores tibble 'variable' 'scores' columns containing names variables feature importance scores. parameter produced recipe trained. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_forests` object. type character either 'terms' (default) return tibble containing variables removed filter step, 'scores' return scores variable.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_forests.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature selection step using a random forest feature importance scores — step_select_forests","text":"`step_select_forests` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_forests.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature selection step using a random forest feature importance scores — step_select_forests","text":"","code":"library(recipes) library(parsnip)  # load the example iris dataset data(cells, package = \"modeldata\")  # create a preprocessing recipe rec <-  recipe(class ~ ., data = cells[, -1]) %>%  step_select_forests(all_predictors(), outcome = \"class\", top_p = 10,                      threshold = 0.9)  prepped <- prep(rec)  preproc_data <- juice(prepped) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         56 #>  #> Training data contained 2019 data points and no missing data. #>  #> Operations: #>  #> Variable importance feature selection (50 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_infgain.html","id":null,"dir":"Reference","previous_headings":"","what":"Information gain feature selection step — step_select_infgain","title":"Information gain feature selection step — step_select_infgain","text":"`step_select_infgain` creates *specification* recipe step selects subset predictors based scores information gain algorithm. step requires FSelectorRcpp package installed. top `top_p` scoring features, features whose scores occur top percentile `threshold` retained new predictors.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_infgain.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Information gain feature selection step — step_select_infgain","text":"","code":"step_select_infgain(   recipe,   ...,   outcome = NULL,   role = NA,   trained = FALSE,   top_p = NA,   threshold = NA,   type = \"infogain\",   nbins = 5,   threads = 1,   exclude = NULL,   scores = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_infgain\") )  # S3 method for step_select_infgain tidy(x, type = \"terms\", ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_infgain.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Information gain feature selection step — step_select_infgain","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables affected step. See selections() details. tidy method, currently used. outcome character string name response variable use evaluate information gain value predictors. role used step since new variables created. trained logical indicate quantities preprocessing estimated. top_p integer number best scoring features select. threshold numeric value 0 1 representing percentile best scoring features select. Features scores _larger_ specified threshold retained, example `threshold = 0.9` retain predictors scores top 90th percentile. Note overrides `top_p`. type character either 'terms' (default) return tibble containing variables removed filter step, 'scores' return scores variable. nbins integer specifying number bins discretization. used outcome continuous variable regression. default 'nbins = 5'. threads integer specifying number threads use processing. default = 0 uses available threads. exclude character vector predictor names removed data. set `prep()` used recipe set user. scores tibble 'variable' 'scores' columns containing names variables information gain scores. parameter produced recipe trained. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_infgain` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_infgain.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Information gain feature selection step — step_select_infgain","text":"step_select_infgain object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_infgain.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Information gain feature selection step — step_select_infgain","text":"recipe stop `top_p` `threshold` left unspecified.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_infgain.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Information gain feature selection step — step_select_infgain","text":"","code":"library(recipes)  data(cells, package = \"modeldata\")  rec <-  recipe(class ~ ., data = cells[, -1]) %>%  step_select_infgain(    all_predictors(),    outcome = \"class\",    top_p = 10,    threshold = 0.9  )  prepped <- prep(rec)  new_data <- juice(prepped) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         56 #>  #> Training data contained 2019 data points and no missing data. #>  #> Operations: #>  #> Information Gain feature selection (50 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_linear.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature selection step using the magnitude of a linear models' coefficients — step_select_linear","title":"Feature selection step using the magnitude of a linear models' coefficients — step_select_linear","text":"`step_select_linear` creates *specification* recipe step selects subset predictors based ranking magnitude coefficients provided `parsnip::linear_reg` `parsnip::logistic_reg` model.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_linear.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature selection step using the magnitude of a linear models' coefficients — step_select_linear","text":"","code":"step_select_linear(   recipe,   ...,   outcome = NULL,   role = \"predictor\",   trained = FALSE,   engine = \"glm\",   penalty = NULL,   mixture = NULL,   top_p = NA,   threshold = NA,   exclude = NULL,   scores = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_linear\") )  # S3 method for step_select_linear tidy(x, type = \"terms\", ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_linear.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature selection step using the magnitude of a linear models' coefficients — step_select_linear","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables affected step. See selections() details. tidy method, currently used. outcome character string name response variable use calculate feature importance scores. role used step since new variables created. trained logical indicate quantities preprocessing estimated. engine supported rand_forest engine supported parsnip. default \"glm\". penalty non-negative number representing total amount regularization (specific engines ). mixture number zero one (inclusive) proportion L1 regularization (.e. lasso) model. mixture = 1, pure lasso model mixture = 0 indicates ridge regression used (specific engines ). top_p integer number best scoring features select. threshold numeric value 0 1 representing percentile best scoring features select. Features scores _larger_ specified threshold retained, example `threshold = 0.9` retain predictors scores top 90th percentile. Note overrides `top_p`. exclude character vector predictor names removed data. set `prep()` used recipe set user. scores tibble 'variable' 'scores' columns containing names variables feature importance scores. parameter produced recipe trained. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_linear` object. type character either 'terms' (default) return tibble containing variables removed filter step, 'scores' return scores variable.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_linear.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature selection step using the magnitude of a linear models' coefficients — step_select_linear","text":"`step_select_linear` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_linear.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature selection step using the magnitude of a linear models' coefficients — step_select_linear","text":"","code":"library(recipes) library(parsnip)  # load the example iris dataset data(cells, package = \"modeldata\")  # create a preprocessing recipe rec <-  recipe(class ~ ., data = cells[, -1]) %>%  step_select_linear(    all_predictors(),    outcome = \"class\",    top_p = 10,    threshold = 0.9  )  prepped <- prep(rec)  preproc_data <- bake(prepped, new_data = NULL) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         56 #>  #> Training data contained 2019 data points and no missing data. #>  #> Operations: #>  #> Variable importance feature selection (50 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_mrmr.html","id":null,"dir":"Reference","previous_headings":"","what":"Apply minimum Redundancy Maximum Relevance Feature Selection (mRMR) — step_select_mrmr","title":"Apply minimum Redundancy Maximum Relevance Feature Selection (mRMR) — step_select_mrmr","text":"`step_select_mrmr` creates *specification* recipe step apply minimum Redundancy Maximum Relevance Feature Selection (mRMR) numeric data. top `top_p` scoring features, features whose scores occur top percentile `threshold` retained new predictors.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_mrmr.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Apply minimum Redundancy Maximum Relevance Feature Selection (mRMR) — step_select_mrmr","text":"","code":"step_select_mrmr(   recipe,   ...,   outcome = NULL,   role = NA,   trained = FALSE,   top_p = NA,   threshold = NA,   threads = 0,   exclude = NULL,   scores = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_mrmr\") )  # S3 method for step_select_mrmr tidy(x, type = \"terms\", ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_mrmr.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Apply minimum Redundancy Maximum Relevance Feature Selection (mRMR) — step_select_mrmr","text":"recipe recipe object. step added sequence operations recipe ... One selector functions choose variables affected step. See selections() details. tidy method, currently used outcome character string specifying name response variable used evaluate mRMR. role used step since new variables created trained logical indicate quantities preprocessing estimated top_p integer used select number best scoring features. threshold numeric value 0 1 representing percentile best scoring features select. Features scores _larger_ specified threshold retained, example `threshold = 0.9` retain predictors scores top 90th percentile. Note overrides `top_p`. threads integer specifying number threads use processing. default = 0 uses available threads. exclude character vector predictor names removed data. set `prep()` used recipe set user. scores tibble 'variable' 'scores' columns containing names variables mRMR scores. parameter produced recipe trained. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_mrmr` object. type character either 'terms' (default) return tibble containing variables removed filter step, 'scores' return scores variable.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_mrmr.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Apply minimum Redundancy Maximum Relevance Feature Selection (mRMR) — step_select_mrmr","text":"step_select_mrmr object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_mrmr.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Apply minimum Redundancy Maximum Relevance Feature Selection (mRMR) — step_select_mrmr","text":"recipe stop `top_p` `threshold` left unspecified.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_mrmr.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Apply minimum Redundancy Maximum Relevance Feature Selection (mRMR) — step_select_mrmr","text":"","code":"library(recipes)  data(cells, package = \"modeldata\")  rec <-  recipe(class ~ ., data = cells[, -1]) %>%  step_select_mrmr(    all_predictors(),    outcome = \"class\",    top_p = 10,    threshold = 0.9  )  prepped <- prep(rec)  new_data <- bake(prepped, new_data = NULL) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         56 #>  #> Training data contained 2019 data points and no missing data. #>  #> Operations: #>  #> mRMR feature selection (50 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_relief.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature selection step using the Relief algorithm — step_select_relief","title":"Feature selection step using the Relief algorithm — step_select_relief","text":"Relief-based algorithms use nearest neighbors randomly sampled observations (without replacement) derive feature weights/scores describe relevance feature target variable. feature weights represent differences normalized feature values randomly sampled observation neighboring observation. neighboring observation's class sampled observation (termed 'hit') feature values different, reduces score basis widely varying feature values class desirable. Conversely, neighboring observation's class different sampled observation (termed 'miss') feature values different, increases score basis observations different classes widely separated feature values. feature weights / scores range -1 (worst) +1 (best).","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_relief.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature selection step using the Relief algorithm — step_select_relief","text":"","code":"step_select_relief(   recipe,   ...,   outcome = NULL,   role = NA,   trained = FALSE,   top_p = NA,   threshold = NA,   neighbors = 5,   sample_size = 10,   exclude = NULL,   scores = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_relief\") )  # S3 method for step_select_relief tidy(x, ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_relief.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature selection step using the Relief algorithm — step_select_relief","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables affected step. See selections() details. tidy method, currently used. outcome character string name response variable use evaluate information gain value predictors. role used step since new variables created. trained logical indicate quantities preprocessing estimated. top_p integer number best scoring features select. threshold numeric value 0 1 representing percentile best scoring features select. Features scores _larger_ specified threshold retained, example `threshold = 0.9` retain predictors scores top 90th percentile. Note overrides `top_p`. neighbors integer number neighbors find sampled instance. Default 5. sample_size integer number instances sample. Default 10. exclude character vector predictor names removed data. set `prep()` used recipe set user. scores tibble 'variable' 'scores' columns containing names variables information gain scores. parameter produced recipe trained. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_relief` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_relief.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature selection step using the Relief algorithm — step_select_relief","text":"step_select_relief object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_relief.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Feature selection step using the Relief algorithm — step_select_relief","text":"`step_select_relief` creates *specification* recipe step selects subset predictors based scores relief algorithm. step requires FSinR package installed. top `top_p` scoring features, features whose scores occur top percentile `threshold` retained new predictors. recipe stop `top_p` `threshold` left unspecified.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_relief.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature selection step using the Relief algorithm — step_select_relief","text":"","code":"library(recipes)  data(cells, package = \"modeldata\")  rec <-  recipe(class ~ ., data = cells[, -1]) %>%  step_select_relief(    all_predictors(),    outcome = \"class\",    top_p = 10,    threshold = 0.9  ) #> 1 package is needed for this step and is not installed. (FSinR). Start a clean R session then run: install.packages(\"FSinR\")  prepped <- prep(rec)  new_data <- bake(prepped, new_data = NULL) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         56 #>  #> Training data contained 2019 data points and no missing data. #>  #> Operations: #>  #> Relief feature selection (50 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_roc.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Numeric Predictors using ROC Curve — step_select_roc","title":"Filter Numeric Predictors using ROC Curve — step_select_roc","text":"`step_select_roc` creates *specification* recipe step  filter predictors using relationship outcome measured  using Receiver Operating Characteristic curve.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_roc.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Numeric Predictors using ROC Curve — step_select_roc","text":"","code":"step_select_roc(   recipe,   ...,   outcome,   role = \"predictor\",   trained = FALSE,   threshold = NA,   top_p = NA,   exclude = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_roc\") )  # S3 method for step_select_roc tidy(x, ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_roc.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Numeric Predictors using ROC Curve — step_select_roc","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose predictors affected step. See [selections()] details. `tidy` method, currently used. outcome single character string specifies single categorical variable used class. role model terms created step, analysis role assigned?. default, function assumes resulting distances used predictors model. trained logical indicate quantities preprocessing estimated. threshold numeric value, AUC units, predictors ROC AUC values _larger_ threshold retained. value `NA` implies criterion ignored. top_p integer used select predictors largest ROC AUC values. value `NA` implies criterion ignored. exclude character vector predictor names removed data. set `prep()` used recipe set user. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_roc` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_roc.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Numeric Predictors using ROC Curve — step_select_roc","text":"updated version `recipe` new step  added sequence existing steps ().  `tidy` method, tibble `terms` column predictors removed.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_roc.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter Numeric Predictors using ROC Curve — step_select_roc","text":"recipe stop `top_p` `threshold` left unspecified. ROC AUC set 1 - AUC value less 0.50.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_roc.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter Numeric Predictors using ROC Curve — step_select_roc","text":"","code":"data(cells, package = \"modeldata\")  rec <-   recipe(class ~ ., data = cells[, -1]) %>%   step_select_roc(all_predictors(), outcome = \"class\", top_p = 10, threshold = 0.9) %>%   prep()  rec %>% bake(all_predictors(), new_data = NULL) %>% names() #>  [1] \"avg_inten_ch_1\"               \"avg_inten_ch_2\"               #>  [3] \"convex_hull_area_ratio_ch_1\"  \"convex_hull_perim_ratio_ch_1\" #>  [5] \"entropy_inten_ch_1\"           \"fiber_width_ch_1\"             #>  [7] \"shape_p_2_a_ch_1\"             \"total_inten_ch_1\"             #>  [9] \"total_inten_ch_2\"             \"var_inten_ch_1\"                # Use ROC values to select but always keep at least one: rec <-   recipe(class ~ ., data = cells[, -1]) %>%   step_select_roc(     all_predictors(),     outcome = \"class\",     top_p = 1,     threshold = 0.99   ) %>%   prep()  rec %>% juice(all_predictors()) %>% names() #> [1] \"fiber_width_ch_1\""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_tree.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature selection step using a decision tree importance scores — step_select_tree","title":"Feature selection step using a decision tree importance scores — step_select_tree","text":"`step_select_tree` creates *specification* recipe step selects subset predictors based ranking variable importance provided `parsnip::decision_tree` supported model.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_tree.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature selection step using a decision tree importance scores — step_select_tree","text":"","code":"step_select_tree(   recipe,   ...,   outcome = NULL,   role = \"predictor\",   trained = FALSE,   engine = \"rpart\",   cost_complexity = NULL,   tree_depth = NULL,   min_n = NULL,   top_p = NA,   threshold = NA,   exclude = NULL,   scores = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_tree\") )  # S3 method for step_select_tree tidy(x, type = \"terms\", ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_tree.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature selection step using a decision tree importance scores — step_select_tree","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables affected step. See selections() details. tidy method, currently used. outcome character string name response variable use calculate feature importance scores. role used step since new variables created. trained logical indicate quantities preprocessing estimated. engine supported rand_forest engine supported parsnip. default \"rpart\". cost_complexity positive number cost/complexity parameter (.k.. Cp) used CART models (specific engines ). tree_depth integer maximum depth tree. min_n integer minimum number data points node required node split . top_p integer number best scoring features select. threshold numeric value 0 1 representing percentile best scoring features select. Features scores _larger_ specified threshold retained, example `threshold = 0.9` retain predictors scores top 90th percentile. Note overrides `top_p`. exclude character vector predictor names removed data. set `prep()` used recipe set user. scores tibble 'variable' 'scores' columns containing names variables feature importance scores. parameter produced recipe trained. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_tree` object. type character either 'terms' (default) return tibble containing variables removed filter step, 'scores' return scores variable.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_tree.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature selection step using a decision tree importance scores — step_select_tree","text":"`step_select_tree` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_tree.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature selection step using a decision tree importance scores — step_select_tree","text":"","code":"library(recipes) library(parsnip)  # load the example cells dataset data(cells, package = \"modeldata\")  # create a preprocessing recipe rec <-  recipe(class ~ ., data = cells[, -1]) %>%  step_select_tree(all_predictors(), outcome = \"class\", top_p = 10,                   threshold = 0.9)  prepped <- prep(rec)  preproc_data <- bake(prepped, new_data = NULL) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         56 #>  #> Training data contained 2019 data points and no missing data. #>  #> Operations: #>  #> Variable importance feature selection (21 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_vip.html","id":null,"dir":"Reference","previous_headings":"","what":"Feature selection step using a model's feature importance scores or\ncoefficients — step_select_vip","title":"Feature selection step using a model's feature importance scores or\ncoefficients — step_select_vip","text":"`step_select_vip` creates *specification* recipe step selects subset predictors based ranking variable importance provided `parsnip` model specification `model` parameter","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_vip.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Feature selection step using a model's feature importance scores or\ncoefficients — step_select_vip","text":"","code":"step_select_vip(   recipe,   ...,   outcome = NULL,   role = \"predictor\",   trained = FALSE,   model = NULL,   top_p = NA,   threshold = NA,   exclude = NULL,   scores = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_vip\") )  # S3 method for step_select_vip tidy(x, type = \"terms\", ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_vip.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Feature selection step using a model's feature importance scores or\ncoefficients — step_select_vip","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose variables affected step. See selections() details. tidy method, currently used. outcome character string name response variable use calculate feature importance scores. role used step since new variables created. trained logical indicate quantities preprocessing estimated. model `model_spec` object `parsnip` feature importances coefficients method. model needs equivalent `pull_importances` method defined. See `?pull_importances` define methods models currently supported. top_p integer number best scoring features select. threshold numeric value 0 1 representing percentile best scoring features select. Features scores _larger_ specified threshold retained, example `threshold = 0.9` retain predictors scores top 90th percentile. Note overrides `top_p`. exclude character vector predictor names removed data. set `prep()` used recipe set user. scores tibble 'variable' 'scores' columns containing names variables feature importance scores. parameter produced recipe trained. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_vip` object type character either 'terms' (default) return tibble containing variables removed filter step, 'scores' return scores variable.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_vip.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Feature selection step using a model's feature importance scores or\ncoefficients — step_select_vip","text":"`step_select_vip` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_vip.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Feature selection step using a model's feature importance scores or\ncoefficients — step_select_vip","text":"","code":"library(recipes) library(parsnip)  # load the example cells dataset data(cells, package = \"modeldata\")  # define a base model to use for feature importances base_model <- rand_forest(mode = \"classification\") %>%     set_engine(\"ranger\", importance = \"permutation\")  # create a preprocessing recipe rec <-  recipe(class ~ ., data = cells[, -1]) %>%  step_select_vip(    all_predictors(),    outcome = \"class\",    model = base_model,    top_p = 10,    threshold = 0.9  )  prepped <- prep(rec)  preproc_data <- juice(prepped) prepped #> Recipe #>  #> Inputs: #>  #>       role #variables #>    outcome          1 #>  predictor         56 #>  #> Training data contained 2019 data points and no missing data. #>  #> Operations: #>  #> Variable importance feature selection (50 excluded)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_xtab.html","id":null,"dir":"Reference","previous_headings":"","what":"Filter Categorical Predictors using Contingency Tables — step_select_xtab","title":"Filter Categorical Predictors using Contingency Tables — step_select_xtab","text":"`step_select_xtab` creates *specification* recipe step  filter predictors using relationship outcome measured  using statistical tests association.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_xtab.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Filter Categorical Predictors using Contingency Tables — step_select_xtab","text":"","code":"step_select_xtab(   recipe,   ...,   outcome,   role = \"predictor\",   trained = FALSE,   threshold = NA,   top_p = NA,   exact = FALSE,   fdr = TRUE,   exclude = NULL,   skip = FALSE,   id = recipes::rand_id(\"select_xtab\") )  # S3 method for step_select_xtab tidy(x, ...)"},{"path":"https://stevenpawley.github.io/colino/reference/step_select_xtab.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Filter Categorical Predictors using Contingency Tables — step_select_xtab","text":"recipe recipe object. step added sequence operations recipe. ... One selector functions choose predictors affected step. See [selections()] details. `tidy` method, currently used. outcome single character string specifies single categorical variable used class. role model terms created step, analysis role assigned?. default, function assumes resulting distances used predictors model. trained logical indicate quantities preprocessing estimated. threshold numeric value, p-value/FDR units, predictors _smaller_ threshold retained. value `NA` implies criterion ignored. top_p integer used select predictors smallest p/FDR values. value `NA` implies criterion ignored. exact exact test used? fdr false discovery rates (FDR) used instead p-values? exclude character vector predictor names removed data. set `prep()` used recipe set user. skip logical. step skipped recipe baked bake.recipe()? operations baked prep.recipe() run, operations may able conducted new data (e.g. processing outcome variable(s)). Care taken using skip = TRUE may affect computations subsequent operations. id character string unique step identify . x `step_select_xtab` object.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_xtab.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Filter Categorical Predictors using Contingency Tables — step_select_xtab","text":"updated version `recipe` new step added  sequence existing steps (). `tidy` method, tibble  `terms` column predictors removed.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_xtab.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Filter Categorical Predictors using Contingency Tables — step_select_xtab","text":"recipe stop `top_p` `threshold` left unspecified. used, combined via ''. Benjamini-Hochberg FDR correction used (see [stats::p.adjust()]). Warnings [stats::chisq.test()] [stats::fisher.test()] suppressed.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/step_select_xtab.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Filter Categorical Predictors using Contingency Tables — step_select_xtab","text":"","code":"data(attrition, package = \"modeldata\")  rec <-   recipe(Attrition ~ ., data = attrition) %>%   step_select_xtab(all_nominal(), -all_outcomes(), outcome = \"Attrition\",                    top_p = 1, threshold = 0.001, exact = TRUE) %>%   prep()  rec %>% juice(all_nominal(), -all_outcomes()) %>% names() #> [1] \"BusinessTravel\"          \"EnvironmentSatisfaction\" #> [3] \"JobInvolvement\"          \"MaritalStatus\"           #> [5] \"OverTime\"                 tidy(rec, number = 1) #> # A tibble: 9 × 2 #>   terms                    id                #>   <chr>                    <chr>             #> 1 JobSatisfaction          select_xtab_kj2Io #> 2 WorkLifeBalance          select_xtab_kj2Io #> 3 Department               select_xtab_kj2Io #> 4 RelationshipSatisfaction select_xtab_kj2Io #> 5 Gender                   select_xtab_kj2Io #> 6 Education                select_xtab_kj2Io #> 7 PerformanceRating        select_xtab_kj2Io #> 8 EducationField           select_xtab_kj2Io #> 9 JobRole                  select_xtab_kj2Io"},{"path":"https://stevenpawley.github.io/colino/reference/top_p.html","id":null,"dir":"Reference","previous_headings":"","what":"Parameter functions for feature selection recipes — top_p","title":"Parameter functions for feature selection recipes — top_p","text":"Feature selection recipes allow top-performing features selected using two parameters. `top_p` specifying number top-performing features.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/top_p.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Parameter functions for feature selection recipes — top_p","text":"","code":"top_p(range = c(1L, 4L), trans = NULL)"},{"path":"https://stevenpawley.github.io/colino/reference/top_p.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Parameter functions for feature selection recipes — top_p","text":"range two-element vector holding _defaults_ smallest largest possible values, respectively. trans `trans` object `scales` package, `scales::log10_trans()` `scales::reciprocal_trans()`. provided, default used matches units used `range`. transformation, `NULL`.","code":""},{"path":"https://stevenpawley.github.io/colino/reference/top_p.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Parameter functions for feature selection recipes — top_p","text":"function classes \"quant_param\" \"param\"","code":""},{"path":"https://stevenpawley.github.io/colino/reference/top_p.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Parameter functions for feature selection recipes — top_p","text":"","code":"top_p(c(3, 10)) #> # Selected Predictors (quantitative) #> Range: [3, 10]"}]
